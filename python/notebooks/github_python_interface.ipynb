{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GITHUB/PYTHON INTERFACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - RUNNING THE PYTHON SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing files were updated\n",
      "0 new files found. No further action necessary\n"
     ]
    }
   ],
   "source": [
    "%run pycovid.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to generate a new Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pycovidfunc' from 'pycovid' (C:\\Users\\user\\Documents\\GitHub\\COVID-19\\python\\notebooks\\pycovid.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9276ab58b61c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpycovid\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpycovidfunc\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'pycovidfunc' from 'pycovid' (C:\\Users\\user\\Documents\\GitHub\\COVID-19\\python\\notebooks\\pycovid.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from numpy import where\n",
    "from pycovid import pycovidfunc as cv\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "if 'config.csv' in os.listdir(os.getcwd()):\n",
    "    config = pd.read_csv('config.csv',index_col='var').fillna('-')\n",
    "else:\n",
    "    raise FileNotFoundError('No configuration file \"config.csv\" found.')\n",
    "    \n",
    "who_data_dir = config.loc['who_data_dir'].path\n",
    "who_file_list = os.listdir(who_data_dir)\n",
    "for file in who_file_list:\n",
    "    if not file.endswith('.csv'):\n",
    "        who_file_list.remove(file)\n",
    "\n",
    "try:\n",
    "    df = cv.raw_data_formatter(who_file_list,who_data_dir)\n",
    "    new_date = datetime.strftime(datetime.now().date(),format='%m-%d-%Y')\n",
    "\n",
    "    raw_data_path = config.loc['raw_data'].path\n",
    "    config.loc['raw_data'].last_update = new_date\n",
    "\n",
    "    df.to_csv(raw_data_path, index=False)\n",
    "    config.to_csv('config.csv')\n",
    "\n",
    "    print('new database generated succesfully!')\n",
    "except:\n",
    "    print('process aborted. No new database generated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to generate the consolidated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(raw_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World data report created succesfully!\n"
     ]
    }
   ],
   "source": [
    "country_report = cv.world_data_formatter(df)\n",
    "country_report.to_json(config.loc['formatted_data'].path,orient='records')\n",
    "print('World data report created succesfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - PYTHON PYCOVID.PY SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing files were updated\n",
      "1 new file(s) found. All files appended into the raw data file\n",
      "Creating world data file...\n",
      "World data report created succesfully!\n",
      "-----------\n",
      "list of diff on github repository:\n",
      "Tableau/Covid19.twbx\n",
      "consolidated_data/country_report.json\n",
      "consolidated_data/raw_data.csv\n",
      "python/backup/Covid19.ipynb\n",
      "python/backup/config.csv\n",
      "python/backup/github_python_interface.ipynb\n",
      "python/backup/notebooks/.ipynb_checkpoints/Covid19-checkpoint.ipynb\n",
      "python/backup/notebooks/.ipynb_checkpoints/github_python_interface-checkpoint.ipynb\n",
      "python/backup/notebooks/.ipynb_checkpoints/raw_data-checkpoint.ipynb\n",
      "python/backup/notebooks/Covid19.ipynb\n",
      "python/backup/notebooks/config.csv\n",
      "python/backup/notebooks/github_python_interface.ipynb\n",
      "python/backup/notebooks/pycovid.bat\n",
      "python/backup/notebooks/pycovid/__pycache__/pycovid.cpython-38.pyc\n",
      "python/backup/notebooks/pycovid/__pycache__/pycovidfunc.cpython-37.pyc\n",
      "python/backup/notebooks/pycovid/__pycache__/pycovidfunc.cpython-38.pyc\n",
      "python/backup/notebooks/pycovid/_init__.py\n",
      "python/backup/notebooks/pycovid/pycovid.py\n",
      "python/backup/notebooks/pycovid/pycovidfunc.py\n",
      "python/backup/notebooks/raw_data.ipynb\n",
      "python/backup/raw_data.csv\n",
      "python/backup/raw_data.ipynb\n",
      "python/backup/scripts/config.csv\n",
      "python/backup/scripts/pycovid/__pycache__/pycovid.cpython-38.pyc\n",
      "python/backup/scripts/pycovid/__pycache__/pycovidfunc.cpython-37.pyc\n",
      "python/backup/scripts/pycovid/__pycache__/pycovidfunc.cpython-38.pyc\n",
      "python/backup/scripts/pycovid/_init__.py\n",
      "python/backup/scripts/pycovid/pycovid.py\n",
      "python/backup/scripts/pycovid/pycovidfunc.py\n",
      "python/notebooks/config.csv\n",
      "python/notebooks/github_python_interface.ipynb\n",
      "commit to github repository\n",
      "----\n",
      "Commit process succesfull\n",
      "----\n",
      "Repo at None successfully loaded.\n",
      "Repo local path: C:\\Users\\user\\Documents\\GitHub\\COVID-19\n",
      "Repo description: covid19 data analysis git project\n",
      "Repo active branch: master\n",
      "Remote named \"origin\" with URL \"https://github.com/psychopresley/COVID-19.git\"\n",
      "Remote named \"upstream\" with URL \"https://github.com/CSSEGISandData/COVID-19.git\"\n",
      "Last commit for repo: a924b786d69f259015793885799361c1373d23d7.\n",
      "----\n",
      "commit: a924b786d69f259015793885799361c1373d23d7\n",
      "\"automated update 2020-07-28 07h53m\" by psychopresley (psychopresley@gmail.com)\n",
      "2020-07-28 07:53:38-03:00\n",
      "count: 1515 and size: 260\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pycovid import pycovidfunc as cv\n",
    "\n",
    "git_dir = r\"C:\\Program Files\\Git\\cmd\"\n",
    "git_bin = os.path.join(git_dir, \"git\")\n",
    "\n",
    "os.putenv(\"GIT_PYTHON_GIT_EXECUTABLE\", git_bin)\n",
    "os.environ.putenv(\"GIT_PYTHON_GIT_EXECUTABLE\", git_bin)\n",
    "\n",
    "# Making sure that it is first in PATH\n",
    "sys.path = [git_dir] + sys.path\n",
    "os.environ[\"PATH\"] = os.pathsep.join([git_dir]) + os.pathsep + os.environ[\"PATH\"]\n",
    "\n",
    "# Only import git now, because that's when the path is checked!\n",
    "import git\n",
    "\n",
    "# Read the config file to check for data file information:\n",
    "\n",
    "if 'config.csv' in os.listdir(os.getcwd()):\n",
    "    config = pd.read_csv('config.csv',index_col='var').fillna('-')\n",
    "else:\n",
    "    raise FileNotFoundError('No configuration file \"config.csv\" found.')\n",
    "\n",
    "who_data_dir = config.loc['who_data_dir'].path\n",
    "repo = git.Repo(config.loc['git_repo'].path)\n",
    "upstream_repo = repo.remotes.upstream\n",
    "\n",
    "# Pull upstream base repo and check for modified files:\n",
    "lm_frame = cv.get_date_modified(who_data_dir)\n",
    "\n",
    "g = git.Git(upstream_repo)\n",
    "g.pull('upstream','master')\n",
    "\n",
    "repo = git.Repo(config.loc['git_repo'].path)\n",
    "lm_after_git_pull = cv.get_date_modified(who_data_dir)\n",
    "\n",
    "count_modified = 0\n",
    "for idx in lm_frame.index:\n",
    "    new_last_modified = lm_after_git_pull.loc[idx].last_modified\n",
    "    if lm_frame.loc[idx].last_modified != new_last_modified:\n",
    "        count_modified += 1\n",
    "\n",
    "who_file_list = os.listdir(who_data_dir)\n",
    "for file in who_file_list:\n",
    "    if not file.endswith('.csv'):\n",
    "        who_file_list.remove(file)\n",
    "\n",
    "\n",
    "flag = True # flag to indicate update\n",
    "report = []\n",
    "if count_modified != 0:\n",
    "    report.append('{} existing file(s) were updated since last pull'.format(count_modified))\n",
    "    report.append('generating new database...')\n",
    "    try:\n",
    "        df = cv.raw_data_formatter(who_file_list,who_data_dir)\n",
    "        new_date = pd.to_datetime(who_file_list[-1].split(sep='.')[0])\n",
    "        last_update = datetime.strftime(new_date,format='%m-%d-%Y')\n",
    "        \n",
    "        raw_data_path = config.loc['raw_data'].path\n",
    "        config.loc['raw_data'].last_update = new_date\n",
    "\n",
    "        df.to_csv(raw_data_path, index=False)\n",
    "        config.to_csv('config.csv')\n",
    "\n",
    "        report.append('new database generated succesfully!')\n",
    "    except:\n",
    "        print('process aborted. No new database generated.')\n",
    "else:\n",
    "    last_update = pd.to_datetime(config.loc['raw_data'].last_update)\n",
    "    latest_who_file_date = pd.to_datetime(who_file_list[-1].split(sep='.')[0])\n",
    "\n",
    "    files_to_update = (latest_who_file_date - last_update).days\n",
    "\n",
    "    # Generating the list of new files to update the database\n",
    "    if files_to_update != 0:\n",
    "        list_of_new_files = []\n",
    "        for i in list(range(1,files_to_update + 1)):\n",
    "            new_date = datetime.strftime((last_update\n",
    "                                          + timedelta(days=i)).date(),\n",
    "                                          format='%m-%d-%Y')\n",
    "            list_of_new_files.append(new_date + '.csv')\n",
    "    \n",
    "        # Generating a dataframe with new information:\n",
    "        df = cv.raw_data_formatter(list_of_new_files,who_data_dir)\n",
    "\n",
    "        # Appending the new data to existing raw data file and updating\n",
    "        # the raw data information in the config file:\n",
    "\n",
    "        raw_data_path = config.loc['raw_data'].path\n",
    "        config.loc['raw_data'].last_update = new_date\n",
    "\n",
    "        df.to_csv(raw_data_path, mode='a', index=False, header=None)\n",
    "        config.to_csv('config.csv')\n",
    "        print('No existing files were updated')\n",
    "        print('%d new file(s) found. All files appended into the raw data file' \n",
    "              % (files_to_update))\n",
    "    else:\n",
    "        flag = False\n",
    "        print('No existing files were updated')\n",
    "        print('0 new files found. No further action necessary')\n",
    "\n",
    "# Create the world data report from the raw data if any update in the raw data file:\n",
    "if flag:\n",
    "    print('Creating world data file...')\n",
    "    try:\n",
    "        df = pd.read_csv(config.loc['raw_data'].path)\n",
    "        country_report = cv.world_data_formatter(df)\n",
    "        country_report.to_json(config.loc['formatted_data'].path,orient='records')\n",
    "        print('World data report created succesfully!')\n",
    "\n",
    "        new_date = pd.to_datetime(who_file_list[-1].split(sep='.')[0])\n",
    "        last_update = datetime.strftime(new_date,format='%m-%d-%Y')\n",
    "\n",
    "        config.loc['formatted_data'].last_update = last_update\n",
    "        config.to_csv('config.csv')\n",
    "        \n",
    "        # Commit changes to github:\n",
    "        print('-----------')\n",
    "        print('list of diff on github repository:')\n",
    "        print(repo.git.diff(None, name_only=True))\n",
    "        print('commit to github repository')\n",
    "        cv.commit_to_repo(repo)\n",
    "        cv.repo_info(repo)\n",
    "    except:\n",
    "        print('World data report creation aborted. Please verify the raw data file.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "headcommit = repo.head.commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "git_dir = r\"C:\\Program Files\\Git\\cmd\"\n",
    "git_bin = os.path.join(git_dir, \"git\")\n",
    "\n",
    "os.putenv(\"GIT_PYTHON_GIT_EXECUTABLE\", git_bin)\n",
    "os.environ.putenv(\"GIT_PYTHON_GIT_EXECUTABLE\", git_bin)\n",
    "\n",
    "# Making sure that it is first in PATH\n",
    "sys.path = [git_dir] + sys.path\n",
    "os.environ[\"PATH\"] = os.pathsep.join([git_dir]) + os.pathsep + os.environ[\"PATH\"]\n",
    "\n",
    "# Only import git now, because that's when the path is checked!\n",
    "import git\n",
    "\n",
    "# Read the config file to check for data file information:\n",
    "\n",
    "if 'config.csv' in os.listdir(os.getcwd()):\n",
    "    config = pd.read_csv('config.csv',index_col='var').fillna('-')\n",
    "else:\n",
    "    raise FileNotFoundError('No configuration file \"config.csv\" found.')\n",
    "\n",
    "who_data_dir = config.loc['who_data_dir'].path\n",
    "repo = git.Repo(config.loc['git_repo'].path)\n",
    "upstream_repo = repo.remotes.upstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commit_to_repo(repo, message=None, log=None):\n",
    "    '''\n",
    "    This function commits to the git repository active branch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    repo: obj, gitpython\n",
    "        gitpython object containing the git repository data\n",
    "    '''\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    git_dir = r\"C:\\Program Files\\Git\\cmd\"\n",
    "    git_bin = os.path.join(git_dir, \"git\")\n",
    "\n",
    "    os.putenv(\"GIT_PYTHON_GIT_EXECUTABLE\", git_bin)\n",
    "    os.environ.putenv(\"GIT_PYTHON_GIT_EXECUTABLE\", git_bin)\n",
    "\n",
    "    # Making sure that it is first in PATH\n",
    "    sys.path = [git_dir] + sys.path\n",
    "    os.environ[\"PATH\"] = os.pathsep.join([git_dir]) + os.pathsep + os.environ[\"PATH\"]\n",
    "\n",
    "    # Only import git now, because that's when the path is checked!\n",
    "    import git\n",
    "    from datetime import datetime\n",
    "\n",
    "    # Creating commit information for repo index:\n",
    "    now_str = datetime.now()\n",
    "    now_str = datetime.strftime(now_str, format='%Y-%m-%d %Hh%Mm')\n",
    "\n",
    "    if message != None:\n",
    "        summary = message\n",
    "    else:\n",
    "        summary = \"automated update {}\".format(now_str)\n",
    "    \n",
    "    if log is None:\n",
    "        log=[]\n",
    "    \n",
    "    try:\n",
    "        repo.git.add(update=True)\n",
    "        repo.index.commit(summary)\n",
    "        origin = repo.remote(name='origin')\n",
    "        origin.push()\n",
    "        log.append('----\\n')\n",
    "        log.append('Commit process succesfull\\n')\n",
    "        log.append('----\\n')\n",
    "    except:\n",
    "        log.append('----\\n')\n",
    "        log.append('Not able to commit. Please check git information\\n')\n",
    "        log.append('----\\n')\n",
    "    \n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log=commit_to_repo(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.append(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-3cd63bc4cb11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'teste.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'+a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwritelines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not list"
     ]
    }
   ],
   "source": [
    "f = open('teste.txt','+a')\n",
    "f.writelines(a)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y', ['----\\n', 'Commit process succesfull\\n', '----\\n']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
