{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIT PYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from pycovid import pycovidfunc as cv\n",
    "\n",
    "git_dir = r\"C:\\Program Files\\Git\\cmd\"\n",
    "git_bin = os.path.join(git_dir, \"git\")\n",
    "\n",
    "os.putenv(\"GIT_PYTHON_GIT_EXECUTABLE\", git_bin)\n",
    "os.environ.putenv(\"GIT_PYTHON_GIT_EXECUTABLE\", git_bin)\n",
    "\n",
    "# Making sure that it is first in PATH\n",
    "sys.path = [git_dir] + sys.path\n",
    "os.environ[\"PATH\"] = os.pathsep.join([git_dir]) + os.pathsep + os.environ[\"PATH\"]\n",
    "\n",
    "# Only import git now, because that's when the path is checked!\n",
    "import git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the config file to check for data file information:\n",
    "\n",
    "if 'config.csv' in os.listdir(os.getcwd()):\n",
    "    config = pd.read_csv('config.csv',index_col='var').fillna('-')\n",
    "else:\n",
    "    raise FileNotFoundError('No configuration file \"config.csv\" found.')\n",
    "    \n",
    "who_data_dir = config.loc['who_data_dir'].path\n",
    "repo = git.Repo(config.loc['git_repo'].path)\n",
    "\n",
    "# upstream repository\n",
    "upstream_repo = repo.remotes.upstream\n",
    "\n",
    "# Pull upstream base repo and check for modified files:\n",
    "lm_frame = cv.get_date_modified(who_data_dir)\n",
    "\n",
    "g = git.Git(upstream_repo)\n",
    "g.pull('upstream','master')\n",
    "\n",
    "lm_after_git_pull = cv.get_date_modified(who_data_dir)\n",
    "count_modified = 0\n",
    "\n",
    "for idx in lm_frame.index:\n",
    "    new_last_modified = lm_after_git_pull.loc[idx].last_modified\n",
    "    if lm_frame.loc[idx].last_modified != new_last_modified:\n",
    "        count_modified += 1\n",
    "\n",
    "who_file_list = os.listdir(who_data_dir)\n",
    "for file in who_file_list:\n",
    "    if not file.endswith('.csv'):\n",
    "        who_file_list.remove(file)\n",
    "\n",
    "# Compare the latest WHO file to the raw data update information\n",
    "# and calculates the number of files to update:\n",
    "\n",
    "flag = True # flag to indicate update\n",
    "if count_modified != 0:\n",
    "    print('{} existing files were updated since last pull'.format(count_modified))\n",
    "    print('generating new database...')\n",
    "    try:\n",
    "        df = cv.raw_data_formatter(who_file_list,who_data_dir)\n",
    "        new_date = datetime.strftime(datetime.now().date(),format='%m-%d-%Y')\n",
    "        config.loc['raw_data'].last_update = new_date\n",
    "\n",
    "        df.to_csv(raw_data_path, index=False)\n",
    "        config.to_csv('config.csv')\n",
    "\n",
    "        print('new database generated succesfully!')\n",
    "    except:\n",
    "        print('process aborted. No new database generated.')\n",
    "else:\n",
    "    last_update = pd.to_datetime(config.loc['raw_data'].last_update)\n",
    "    latest_who_file_date = pd.to_datetime(who_file_list[-1].split(sep='.')[0])\n",
    "\n",
    "    files_to_update = (latest_who_file_date - last_update).days\n",
    "\n",
    "    # Generating the list of new files to update the database\n",
    "    if files_to_update != 0:\n",
    "        list_of_new_files = []\n",
    "        for i in list(range(1,files_to_update + 1)):\n",
    "            new_date = datetime.strftime((last_update\n",
    "                                          + timedelta(days=i)).date(),\n",
    "                                          format='%m-%d-%Y')\n",
    "            list_of_new_files.append(new_date + '.csv')\n",
    "    \n",
    "        # Generating a dataframe with new information:\n",
    "        df = cv.raw_data_formatter(list_of_new_files,who_data_dir)\n",
    "\n",
    "        # Appending the new data to existing raw data file and updating\n",
    "        # the raw data information in the config file:\n",
    "\n",
    "        raw_data_path = config.loc['raw_data'].path\n",
    "        config.loc['raw_data'].last_update = new_date\n",
    "\n",
    "        df.to_csv(raw_data_path, mode='a', index=False, header=None)\n",
    "        config.to_csv('config.csv')\n",
    "        print('No existing files were updated')\n",
    "        print('%d new file(s) found. All files appended into the raw data file' \n",
    "              % (files_to_update))\n",
    "    else:\n",
    "        flag = False\n",
    "        print('No existing files were updated')\n",
    "        print('0 new files found. No further action necessary')\n",
    "\n",
    "# Create the world data report from the raw data if any update in the raw data file:\n",
    "if flag:\n",
    "    print('Creating world data file...')\n",
    "    try:\n",
    "        df = pd.read_csv(config.loc['raw_data'].path)\n",
    "        country_report = cv.world_data_formatter(df)\n",
    "        country_report.to_json(config.loc['formatted_data'].path,orient='records')\n",
    "        print('World data report created succesfully!')\n",
    "        \n",
    "        # Commit changes to github:\n",
    "        cv.commit_to_repo(repo)\n",
    "        cv.repo_info(repo)\n",
    "    except:\n",
    "        print('World data report creation aborted. Please verify the raw data file.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consolidated_data/raw_data.csv\n",
      "python/notebooks/.ipynb_checkpoints/github_python_interface-checkpoint.ipynb\n",
      "python/notebooks/config.csv\n",
      "python/notebooks/github_python_interface.ipynb\n",
      "python/scripts/pycovid/__pycache__/pycovidfunc.cpython-37.pyc\n",
      "python/scripts/pycovid/pycovidfunc.py\n"
     ]
    }
   ],
   "source": [
    "print(repo.git.diff(None, name_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo at None successfully loaded.\n",
      "Repo local path: C:\\Users\\user\\Documents\\GitHub\\COVID-19\n",
      "Repo description: covid19 data analysis git project\n",
      "Repo active branch: master\n",
      "Remote named \"origin\" with URL \"https://github.com/psychopresley/COVID-19.git\"\n",
      "Remote named \"upstream\" with URL \"https://github.com/CSSEGISandData/COVID-19.git\"\n",
      "Last commit for repo: 62232049bdb6b9774359daaaf676316a0c0f38f1.\n",
      "----\n",
      "commit: 62232049bdb6b9774359daaaf676316a0c0f38f1\n",
      "\"integrating gitpython with raw data treatment Part II: 07-17-2020\" by psychopresley (psychopresley@gmail.com)\n",
      "2020-07-17 22:13:56-03:00\n",
      "count: 1375 and size: 291\n"
     ]
    }
   ],
   "source": [
    "cv.repo_info(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "headcommit = repo.head.commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
